{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oembed = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "db = FAISS.from_texts(documents, oembed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"mistral:latest\")\n",
    "memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=model,\n",
    "    retriever=db.as_retriever(),\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What animals are llamas related to?', 'chat_history': [HumanMessage(content='What animals are llamas related to?'), AIMessage(content=' Llamas are related to camelids, which is a family that includes vicuñas and camels.')], 'answer': ' Llamas are related to camelids, which is a family that includes vicuñas and camels.'}\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What animals are llamas related to?\"\n",
    "print(conversation_chain.invoke({'question': user_question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ImageNet Classiﬁcation with Deep Convolutional\\nNeural Networks\\nAlex Krizhevsky\\nUniversity of Toronto\\nkriz@cs.utoronto.caIlya Sutskever\\nUniversity of Toronto\\nilya@cs.utoronto.caGeoffrey E. Hinton\\nUniversity of Toronto\\nhinton@cs.utoronto.ca\\nAbstract\\nWe trained a large, deep convolutional neural network to classify the 1.2 million\\nhigh-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif-\\nferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5%\\nand 17.0% which is considerably better than the previous state-of-the-art. The\\nneural network, which has 60 million parameters and 650,000 neurons, consists\\nof ﬁve convolutional layers, some of which are followed by max-pooling layers,\\nand three fully-connected layers with a ﬁnal 1000-way softmax. To make train-\\ning faster, we used non-saturating neurons and a very efﬁcient GPU implemen-\\ntation of the convolution operation. To reduce overﬁtting in the fully-connected'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypdf import PdfReader \n",
    "  \n",
    "# creating a pdf reader object \n",
    "reader = PdfReader('./pdf_examples/NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf') \n",
    "  \n",
    "# printing number of pages in pdf file \n",
    "print(len(reader.pages)) \n",
    "  \n",
    "# getting a specific page from the pdf file\n",
    "raw_text = \"\\n\".join([p.extract_text() for p in reader.pages])\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_spliteer = CharacterTextSplitter(separator='\\n',\n",
    "                                        chunk_size=1024, chunk_overlap=256,\n",
    "                                        length_function=len)\n",
    "chunks = text_spliteer.split_text(raw_text)\n",
    "\n",
    "print(len(chunks))\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "oembed = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "db = FAISS.from_texts(chunks, oembed)\n",
    "model = OllamaLLM(model=\"llama3.1:8b\")\n",
    "memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=model,\n",
    "    retriever=db.as_retriever(),\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What model arcitecture do the author of the article used?', 'chat_history': [HumanMessage(content='What this article is about?'), AIMessage(content='This article appears to be a research paper discussing the use of deep convolutional neural networks (CNNs) for image classification, particularly on large-scale datasets such as ImageNet. The authors describe their architecture and methods for achieving record-breaking results on a challenging dataset using supervised learning. They also discuss the benefits of overlapping pooling in CNNs and provide results comparing different pooling schemes.\\n\\nMore specifically, this article seems to be about the development and evaluation of a deep learning model for image classification tasks, with an emphasis on scalability and performance on large datasets.'), HumanMessage(content='What model arcitecture do the author of the article used?'), AIMessage(content='The authors used an architecture with eight learned layers, consisting of five convolutional layers and three fully-connected layers. This is summarized in Figure 2. \\n\\nMore specifically:\\n\\n* The first five layers are convolutional.\\n* The remaining three layers are fully-connected.\\n* The output of the last fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels.\\n* Their network maximizes the multinomial logistic regression objective, which is equivalent to maximizing the average across training cases of the log-probability of the correct label under the prediction distribution.')], 'answer': 'The authors used an architecture with eight learned layers, consisting of five convolutional layers and three fully-connected layers. This is summarized in Figure 2. \\n\\nMore specifically:\\n\\n* The first five layers are convolutional.\\n* The remaining three layers are fully-connected.\\n* The output of the last fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels.\\n* Their network maximizes the multinomial logistic regression objective, which is equivalent to maximizing the average across training cases of the log-probability of the correct label under the prediction distribution.'}\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What model arcitecture do the author of the article used?\"\n",
    "print(conversation_chain.invoke({'question': user_question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Response Normalization (LRN) is a technique used to reduce overfitting in neural networks, particularly in Convolutional Neural Networks (CNNs). It involves normalizing the output of neurons within a small spatial neighborhood, typically centered around each neuron. The normalization process is based on the maximum activity among neighboring neurons, and it helps to prevent any single neuron from dominating the output.\n",
      "\n",
      "In the context provided, LRN is described as being implemented in the form of lateral inhibition inspired by real neurons, creating competition for big activities amongst neuron outputs computed using different kernels. It is applied after applying the ReLU nonlinearity in certain layers and has been shown to reduce top-1 and top-5 error rates by 1.4% and 1.2%, respectively.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Can you explain what is Local Response Normalization?\"\n",
    "print(conversation_chain.invoke({'question': user_question})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
